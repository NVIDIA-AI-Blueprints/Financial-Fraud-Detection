{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial Fraud Detection\n",
    "Brev Launchable with SHAPLEY Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The objective of this notebook is to showcase the usage of the ___financial-fraud-training___ NIM (microservice) (NEED LINK) and how to deploy the produced trained models on the Triton Inference Server.\n",
    "- We use [IBM TabFromer](https://github.com/IBM/TabFormer) as an example dataset\n",
    "- That datset is then preprocess before running through the training NIM.\n",
    "\n",
    "NOTICE:\n",
    "- This notebook assume that you have followed the pre\n",
    "\n",
    "NOTE: The preprocessing code is written specifically for the TabFormer dataset and will not work with other datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r \"./requirements.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Step 1: Get and Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___This example uses the IBM TabFormer dataset.\n",
    "Unfortunatley it is not a simple process to download the dataset. \n",
    "There are a few manual steps needed to access the data___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## How to get a link to the Test Data\n",
    "\n",
    "The origin of the test data this [TabFormer git repository](https://github.com/IBM/TabFormer/tree/main/data/credit_card). The problem is that it is generally not downloadable from this location as it is a large file and is stored / retrieved using git-lfs. Due to the popularity of the file it is generally not able to be downloaded here. As such, the owners of that repository have made the dataset available via [Box](https://ibm.box.com/v/tabformer-data).\n",
    "\n",
    "While this makes it fairly easy to retrieve the file for local use, it does make it a little more difficult to retrieve for the sakes of testing in a container as this application expects. So, there are a few steps to follow to get a download link that you can put into the download box."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "\n",
    "Open a browser window and navigate to the box dataset [https://ibm.box.com/v/tabformer-data](https://ibm.box.com/v/tabformer-data). \n",
    "\n",
    "![Image 1](../docs/images/1.png)\n",
    "\n",
    "Right click in the webpage and select `Inspect`. When the developer tools opens, select the `Network`\n",
    "\n",
    "![Image 2](../docs/images/2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "\n",
    "In the webpage itself, click on the credit_card folder. \n",
    "\n",
    "![Image 3](../docs/images/3.png)\n",
    "\n",
    "You will see `transactions.tgz` when you point at the file a 3-button menu will show up and when you click that 3-button menu, a download dialog will pop up. \n",
    "\n",
    "Click download and after a moment the file should start downloading locally (this is fine, you can delete it after). \n",
    "\n",
    "In the network panel an entry will show up by the name `download`. Click the name `download` and the `Headers` panel will show up. In there you will find `Request URL`. Highlight the entire value (**this is the download URL**) and `copy` the URL. This is a temporary link that is provided. It has a time limit. It will look something like this: `https://public.boxcloud.com/d/1/{LOTS OF RANDOM LOOKING CHARACTERS}/download`\n",
    "\n",
    "![Image 4](../docs/images/4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3\n",
    "\n",
    "In the notebook set the value of `DOWNLOAD_URL` by pasting in the url you copied in step 2: `DOWNLOAD_URL=\"[the pasted url text goes in between these quotes, do not include these brackets]\"`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOAD_URL = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure we are in the \"data\" folder\n",
    "%cd ../data\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget {DOWNLOAD_URL}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv download download.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar xvzf download.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv card_transaction.v1.csv ./TabFormer/raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now have\n",
    "```\n",
    ".\n",
    "    data\n",
    "    └── TabFormer\n",
    "        └── raw\n",
    "            └── card_transaction.v1.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once the raw data is placed as described above, set the path to the TabFormer directory\n",
    "\n",
    "# Change this path to point to TabFormer data\n",
    "data_root_dir = os.path.abspath('../data/TabFormer/') \n",
    "\n",
    "# Change this path to the directory where you want to save your model\n",
    "model_output_dir = os.path.join(data_root_dir, 'trained_models')\n",
    "\n",
    "# Path to save the trained model\n",
    "os.makedirs(model_output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the raw data has been placed properly\n",
    "!tree {data_root_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 2: Preprocess the data and \n",
    "- Import the Python function that handles preprocess the TabFormer data\n",
    "- Call `preprocess_TabFormer` function to prepare the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the \"src\" directory to the search path\n",
    "src_dir = os.path.abspath(os.path.join(os.path.dirname(os.getcwd()), 'src'))\n",
    "sys.path.insert(0, src_dir)\n",
    "\n",
    "# should be able to import from \"src\" folder now\n",
    "from preprocess_TabFormer import proprocess_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "mask_mapping, feature_mask = preprocess_data(data_root_dir)\n",
    "\n",
    "# this will output status as it correlates data and produces catagorical types\n",
    "# the mask_mapping anf feature_mask variable will be used later "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You should not see files under a \"gnn\" folder and under a \"xgb\" folder\n",
    "!tree {data_root_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "# Step 3:  Use the financial-fraud-training NIM to train an XGBoost model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training configuration file\n",
    "NOTE: Training configuration file must conform to the training schemas defined in financial-fraud-training NIM  (NOTE:  NEED A LINK TO THE DOCS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Important: Models and configuration files needed for deployment using the Triton Inference server will be saved in trained_models/model-repository__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_config = {\n",
    "  \"paths\": {\n",
    "    \"data_dir\": \"/data\", # Mount dataset root directory under /data in the container\n",
    "    \"output_dir\": \"/trained_models\" # Mount path to save the trained models.\n",
    "                                    # NOTE: This path is inside the docker container \n",
    "  },\n",
    "\n",
    "  \"models\": [\n",
    "    {\n",
    "      \"kind\": \"GraphSAGE_XGBoost\",\n",
    "      \"gpu\": \"single\",\n",
    "      \"hyperparameters\": {\n",
    "        \"gnn\":{\n",
    "          \"hidden_channels\": 16,\n",
    "          \"n_hops\": 1,\n",
    "          \"dropout_prob\": 0.1,\n",
    "          \"batch_size\": 1024,\n",
    "          \"fan_out\": 16,\n",
    "          \"num_epochs\": 16\n",
    "        },\n",
    "        \"xgb\": {\n",
    "          \"max_depth\": 6,\n",
    "          \"learning_rate\": 0.2,\n",
    "          \"num_parallel_tree\": 3,\n",
    "          \"num_boost_round\": 512,\n",
    "          \"gamma\": 0.0\n",
    "        }\n",
    "\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the training configuration file as a json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_config_file_name = 'training_config.json'\n",
    "\n",
    "with open(os.path.join(training_config_file_name), 'w') as json_file:\n",
    "    json.dump(training_config, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull and run the financial-fraud-training NIM \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY=\"replace with your API key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker login nvcr.io --username '$oauthtoken' --password {API_KEY}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker pull nvcr.io/nvstaging/nim/financial-fraud-training:1.0.0-rc1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a local cache directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = subprocess.run([\"whoami\"], capture_output=True, text=True).stdout.strip()\n",
    "nim_cache_dir = f'/home/{username}/.cache/nim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p {nim_cache_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set container name and ports for running the container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NIM_HTTP_PORT = 8002\n",
    "NIM_GRPC_PORT = 50051\n",
    "CONTAINER_NAME = \"financial-fraud-training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop any running container with the same name\n",
    "!docker stop {CONTAINER_NAME}\n",
    "!docker rm {CONTAINER_NAME}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run -d -it --rm --runtime=nvidia --name={CONTAINER_NAME} --gpus all \\\n",
    "    -p {NIM_HTTP_PORT}:{NIM_HTTP_PORT} -e NIM_HTTP_API_PORT={NIM_HTTP_PORT} -p {NIM_GRPC_PORT}:{NIM_GRPC_PORT} \\\n",
    "    -e NIM_DISABLE_MODEL_DOWNLOAD=True -e NIM_GRPC_API_PORT={NIM_GRPC_PORT} -e NIM_CACHE_PATH=/opt/nim/.cache \\\n",
    "    -e NIM_CACHE_PATH=/opt/nim/.cache  --mount=type=bind,src={nim_cache_dir},dst=/opt/nim/.cache -v {data_root_dir}:/data \\\n",
    "    -v {model_output_dir}:/trained_models nvcr.io/nvstaging/nim/financial-fraud-training:1.0.0-rc1 -e NGC_API_KEY={API_KEY}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, initiate model training using the training configuration defined earlier\n",
    "\n",
    "* Initiate training via the /train endpoint by sending the training configuration as a JSON payload.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = [\n",
    "    \"curl\",\n",
    "    \"-X\", \"POST\",\n",
    "    \"-H\", \"Content-Type: application/json\",\n",
    "    \"-d\", json.dumps(training_config),\n",
    "    f\"http://0.0.0.0:{NIM_HTTP_PORT}/train\"\n",
    "]\n",
    "result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "result.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!curl -X POST \"http://0.0.0.0:$NIM_HTTP_PORT/train\"   -H \"Content-Type: application/json\"   -d @{training_config_file_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make sure that the `model_repository` has been created with right contents in it\n",
    "According the above defined configuration file, the `model_repository`, which is folder containing the models and configuration files to be deployed on the Triton inference Server, will be created under \n",
    "{data_root_dir}/trained_models/ and its contents will look like\n",
    "\n",
    "```sh\n",
    "├── model\n",
    "│   ├── 1\n",
    "│   │   └── graph_sage_node_embedder.onnx\n",
    "│   └── config.pbtxt\n",
    "└── xgboost\n",
    "    ├── 1\n",
    "    │   └── xgboost_on_embeddings.json\n",
    "    └── config.pbtxt\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree {model_output_dir}/model_repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Step 4:  Serve your python backend model on Triton Inference Server\n",
    "\n",
    "!Important: Change MODEL_REPO_PATH to point to the `model python_backend_model_repository` folder if you used different path in your training configuration file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy python backend model¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_locally:\n",
    "    HOST = 'localhost'\n",
    "else:\n",
    "    HOST = '<SERVER_URL>' # Replace with your server URL or IP address\n",
    "\n",
    "HTTP_PORT = 8005\n",
    "GRPC_PORT = 8006\n",
    "METRICS_PORT = 8007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_locally:\n",
    "    \n",
    "    # Triton server image\n",
    "    TRITON_IMAGE = 'nvcr.io/nvidia/tritonserver:25.01-py3'\n",
    "    MODEL_REPO_PATH = os.path.join(model_output_dir, 'python_backend_model_repository')\n",
    "\n",
    "    # Pull docker \n",
    "    !docker pull {TRITON_IMAGE}\n",
    "    !docker stop tritonserver\n",
    "    !docker rm tritonserver\n",
    "\n",
    "    !docker run --gpus all -d -p {HTTP_PORT}:{HTTP_PORT} -p {GRPC_PORT}:{GRPC_PORT} \\\n",
    "        -v {MODEL_REPO_PATH}:/models --name tritonserver {TRITON_IMAGE} tritonserver \\\n",
    "        --model-repository=/models   --http-port={HTTP_PORT} --grpc-port={GRPC_PORT} \\\n",
    "        --metrics-port={METRICS_PORT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_grpc = triton_grpc.InferenceServerClient(url=f'{HOST}:{GRPC_PORT}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "container_name = \"tritonserver\"\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        if client_grpc.is_server_ready():\n",
    "            break\n",
    "    except triton_utils.InferenceServerException as e:\n",
    "        pass\n",
    "    try:\n",
    "        # Run the docker logs command with the --tail option\n",
    "        output = subprocess.check_output([\"docker\", \"logs\", \"--tail\", \"10\", container_name])\n",
    "        print(output.decode(\"utf-8\"))\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"Error retrieving logs:\", e)\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction without computing Shapley values¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "model_name = \"prediction_and_shapley\"\n",
    "test_path = os.path.join(data_root_dir, \"xgb/test.csv\") # already preprocessed data\n",
    "test_df = pd.read_csv(test_path)\n",
    "X = test_df.iloc[:, :-1].values.astype(np.float32)\n",
    "y = test_df.iloc[:, -1].values\n",
    "edge_index = np.array([[], []]).astype(np.int64) # empty edge_index\n",
    "compute_shap = np.array([False], dtype=bool) # Skip shap value computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_mask = feature_mask.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with httpclient.InferenceServerClient(f\"localhost:{HTTP_PORT}\") as client:\n",
    "    input_features = httpclient.InferInput(\"NODE_FEATURES\", X.shape, datatype=\"FP32\")\n",
    "    input_features.set_data_from_numpy(X)\n",
    "\n",
    "    input_edge_indices = httpclient.InferInput(\"EDGE_INDEX\", edge_index.shape, datatype=\"INT64\")\n",
    "    input_edge_indices.set_data_from_numpy(edge_index)\n",
    "\n",
    "    input_feature_mask = httpclient.InferInput(\"FEATURE_MASK\", feature_mask.shape, datatype=\"INT32\")\n",
    "    input_feature_mask.set_data_from_numpy(feature_mask)\n",
    "\n",
    "    compute_shap_flag = httpclient.InferInput(\"COMPUTE_SHAP\", compute_shap.shape, datatype=\"BOOL\")\n",
    "    compute_shap_flag.set_data_from_numpy(compute_shap)\n",
    "    \n",
    "    outputs = [\n",
    "        httpclient.InferRequestedOutput(\"PREDICTION\"),\n",
    "        httpclient.InferRequestedOutput(\"SHAP_VALUES\")\n",
    "    ]\n",
    "    response = client.infer(model_name, inputs=[input_features, input_edge_indices, compute_shap_flag, input_feature_mask ], request_id=str(1), outputs=outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions= response.as_numpy('PREDICTION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "y_pred = (predictions > 0.5).astype(int)\n",
    "\n",
    "\n",
    "# Compute evaluation metrics\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "precision = precision_score(y, y_pred, zero_division=0)\n",
    "recall = recall_score(y, y_pred, zero_division=0)\n",
    "f1 = f1_score(y, y_pred, zero_division=0)\n",
    "\n",
    "print(\"----Summary---\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Create a DataFrame with labeled rows and columns\n",
    "classes = ['Non-Fraud', 'Fraud']\n",
    "columns = pd.MultiIndex.from_product([[\"Predicted\"], classes])\n",
    "index = pd.MultiIndex.from_product([[\"Actual\"], classes])\n",
    "\n",
    "conf_mat = confusion_matrix(y, y_pred)\n",
    "cm_df = pd.DataFrame(conf_mat, index=index, columns=columns)\n",
    "print(cm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Plot the confusion matrix directly from predictions\n",
    "disp = ConfusionMatrixDisplay.from_predictions(\n",
    "    y, y_pred, display_labels=classes)\n",
    "disp.ax_.set_title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Shapley value for different features for a transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set COMPUTE_SHAP flag to True\n",
    "compute_shap = np.array([True], dtype=bool)\n",
    "\n",
    "X = test_df.iloc[:1, :-1].values.astype(np.float32)\n",
    "y = test_df.iloc[:1, -1].values\n",
    "\n",
    "with httpclient.InferenceServerClient(f\"localhost:{HTTP_PORT}\") as client:\n",
    "    input_features = httpclient.InferInput(\"NODE_FEATURES\", X.shape, datatype=\"FP32\")\n",
    "    input_features.set_data_from_numpy(X)\n",
    "\n",
    "    input_edge_indices = httpclient.InferInput(\"EDGE_INDEX\", edge_index.shape, datatype=\"INT64\")\n",
    "    input_edge_indices.set_data_from_numpy(edge_index)\n",
    "\n",
    "    input_feature_mask = httpclient.InferInput(\"FEATURE_MASK\", feature_mask.shape, datatype=\"INT32\")\n",
    "    input_feature_mask.set_data_from_numpy(feature_mask)\n",
    "\n",
    "    compute_shap_flag = httpclient.InferInput(\"COMPUTE_SHAP\", compute_shap.shape, datatype=\"BOOL\")\n",
    "    compute_shap_flag.set_data_from_numpy(compute_shap)\n",
    "    \n",
    "    outputs = [\n",
    "        httpclient.InferRequestedOutput(\"PREDICTION\"),\n",
    "        httpclient.InferRequestedOutput(\"SHAP_VALUES\")\n",
    "    ]\n",
    "    response = client.infer(model_name, inputs=[input_features, input_edge_indices, compute_shap_flag, input_feature_mask ], request_id=str(1), outputs=outputs)\n",
    "\n",
    "\n",
    "predictions= response.as_numpy('PREDICTION')\n",
    "shap_values = response.as_numpy('SHAP_VALUES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_to_attribution_map = dict(zip(feature_mask, shap_values[0]))\n",
    "feature_name_to_id_map = {v:k  for k,v in mask_mapping.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shapley values for different features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{feature_name_to_id_map[k]: f\"{v:.3f}\" for k, v in feature_to_attribution_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copyright\n",
    "Copyright (c) 2025, NVIDIA CORPORATION. All rights reserved.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
    "\n",
    "http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cugraph_dev_2504",
   "language": "python",
   "name": "cugraph_dev_2504"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
